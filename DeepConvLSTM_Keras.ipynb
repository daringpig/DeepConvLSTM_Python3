{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import _pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sliding_window import sliding_window\n",
    "\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "NUM_CLASSES = 18\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "FINAL_SEQUENCE_LENGTH = 8\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "BATCH_SIZE = 100\n",
    "NUM_FILTERS = 64\n",
    "FILTER_SIZE = 5\n",
    "NUM_UNITS_LSTM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..after sliding and reshaping, train data: inputs (46495, 24, 113), targets (46495, 18)\n",
      " ..after sliding and reshaping, test data : inputs (9894, 24, 113), targets (9894, 18)\n"
     ]
    }
   ],
   "source": [
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x, (ws, data_x.shape[1]), (ss, 1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y, ws, ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "\n",
    "# Data is reshaped\n",
    "X_train = X_train.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "y_train = np_utils.to_categorical(y_train) # one-hot encoding\n",
    "y_test = np_utils.to_categorical(y_test) # one-hot encoding\n",
    "\n",
    "print(\" ..after sliding and reshaping, train data: inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "print(\" ..after sliding and reshaping, test data : inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/yminoh/DeepConvLSTM_Python3/raw/master/architecture_of_DeepConvLSTM.png)  \n",
    "<div style=\"text-align: center\">Figure 3 from Ordonez and Roggen, 2016</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the Kears layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1D_1 (Conv1D)            (None, 20, 64)            36224     \n",
      "_________________________________________________________________\n",
      "Conv1D_2 (Conv1D)            (None, 16, 64)            20544     \n",
      "_________________________________________________________________\n",
      "Conv1D_3 (Conv1D)            (None, 12, 64)            20544     \n",
      "_________________________________________________________________\n",
      "Conv1D_4 (Conv1D)            (None, 8, 64)             20544     \n",
      "_________________________________________________________________\n",
      "LSTM_1 (LSTM)                (None, 8, 128)            98816     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 8, 128)            131584    \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 18)                18450     \n",
      "=================================================================\n",
      "Total params: 346,706\n",
      "Trainable params: 346,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rmp = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, activation='relu', kernel_initializer='orthogonal',\n",
    "                 input_shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS), \n",
    "                 name='Conv1D_1'))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, activation='relu', kernel_initializer='orthogonal', \n",
    "                 name='Conv1D_2'))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, activation='relu', kernel_initializer='orthogonal', \n",
    "                 name='Conv1D_3'))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, activation='relu', kernel_initializer='orthogonal',\n",
    "                 name='Conv1D_4'))\n",
    "model.add(LSTM(NUM_UNITS_LSTM, return_sequences=True, kernel_initializer='orthogonal', \n",
    "               name='LSTM_1'))\n",
    "model.add(LSTM(NUM_UNITS_LSTM, return_sequences=True, kernel_initializer='orthogonal', \n",
    "               name='LSTM_2'))\n",
    "model.add(Flatten(name='Flatten'))\n",
    "model.add(Dropout(0.5, name='dropout'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax', kernel_initializer='orthogonal', \n",
    "                name='Output'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmp, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/yminoh/DeepConvLSTM_Python3/raw/master/Table1.png)  \n",
    "<div style=\"text-align: center\">Table 1 from Ordonez and Roggen, 2016</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46495 samples, validate on 9894 samples\n",
      "Epoch 1/5\n",
      "46495/46495 [==============================] - 20s - loss: 1.3234 - acc: 0.6927 - val_loss: 0.8281 - val_acc: 0.8325\n",
      "Epoch 2/5\n",
      "46495/46495 [==============================] - 19s - loss: 1.1530 - acc: 0.6933 - val_loss: 0.8172 - val_acc: 0.8325\n",
      "Epoch 3/5\n",
      "46495/46495 [==============================] - 19s - loss: 1.0375 - acc: 0.6988 - val_loss: 0.6575 - val_acc: 0.8426\n",
      "Epoch 4/5\n",
      "46495/46495 [==============================] - 19s - loss: 0.9405 - acc: 0.7239 - val_loss: 0.6951 - val_acc: 0.8242\n",
      "Epoch 5/5\n",
      "46495/46495 [==============================] - 19s - loss: 0.8772 - acc: 0.7340 - val_loss: 0.5858 - val_acc: 0.8392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7978e11780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          epochs=5, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 13, 14, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "test_true = np.argmax(y_test, axis=1)\n",
    "np.unique(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest fscore:\t0.7754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(\"\\tTest fscore:\\t{:.4f} \".format(metrics.f1_score(test_true, test_pred, average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
